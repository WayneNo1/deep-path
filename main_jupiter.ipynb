{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlpf.base_utils import *\n",
    "import gym\n",
    "from dlpf.agents import DqnAgent, RandomAgent, FlatAgent, FlatAgentWithLossLogging\n",
    "import keras\n",
    "from dlpf.io import *\n",
    "from data_shuffle import *\n",
    "\n",
    "logger = init_log(out_file = 'import.log', stderr = False)\n",
    "to_import = False\n",
    "if to_import:\n",
    "    import_tasks_from_xml_to_compact('data/sample/raw/', 'data/sample/imported/')\n",
    "    shuffle_imported_paths(to_split=True, val=False)\n",
    "    shuffle_imported_maps(to_split=True, val=False)\n",
    "\n",
    "logger = init_log(out_file = 'testbed.log', stderr = False)\n",
    "\n",
    "\n",
    "env = gym.make('PathFindingByPixel-v3')\n",
    "env.configure(tasks_dir = os.path.abspath('data/sample/imported/'), monitor_scale = 10)#, map_shape = (10, 10))\n",
    "env.monitor.start('data/sample/results/basic_dqn', force=True, seed=0)\n",
    "agent = FlatAgentWithLossLogging(state_size = env.observation_space.shape,\n",
    "                 number_of_actions = env.action_space.n,\n",
    "                 save_name = env.__class__.__name__)\n",
    "agent.build_model()"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 4,
   "source": [
    "Learning to play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_count = 5000\n",
    "max_steps = 500\n",
    "\n",
    "for _ in xrange(episode_count):\n",
    "    env.mode = 'train'\n",
    "    observation = env.reset()\n",
    "    agent.new_episode()\n",
    "    walls = 0\n",
    "    for __ in range(max_steps):\n",
    "        action, values = agent.act(observation, epsilon=0.05+0.95*0.999**(_))\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if info:\n",
    "            walls += 1\n",
    "        agent.observe(reward, action)\n",
    "        if done:\n",
    "            break\n",
    "    steps = __\n",
    "    print 'GAME #', _+1\n",
    "    if done:\n",
    "        print 'DONE: ', steps, 'moves.',\n",
    "    else:\n",
    "        print 'FAIL: ',\n",
    "    print 'Found', walls, 'walls'\n",
    "    if _ % 100 == 99:\n",
    "        print 'iteration:', _ + 1\n",
    "        agent.plot_layers(to_save='iteration'+str(_+1))\n",
    "    if _ % 10 == 9:\n",
    "        agent.train_with_full_experience()\n",
    "print 'NN finished learning'"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 4,
   "source": [
    "Testing on new maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}